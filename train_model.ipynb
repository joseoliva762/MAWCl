{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import cv2 as cv\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convpool(X, W, b):\n",
    "    conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_out = tf.nn.bias_add(conv_out, b)\n",
    "    pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return tf.nn.relu(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_dataset(ruta):\n",
    "    File = open(ruta, 'rb')\n",
    "    data_x_tmp = pickle.load(File)\n",
    "    data_y = pickle.load(File)\n",
    "    File.close()\n",
    "    del(File)\n",
    "    return data_x_tmp, data_y\n",
    "\n",
    "def show_img(data_x_tmp, data_y, index_img=255):   \n",
    "    plt.imshow(data_x_tmp[index_img])\n",
    "    if data_y[index_img, 0]:\n",
    "        print (\">>> La imagen No. {} está etiquetado como Hombre.\".format(index_img))\n",
    "    else:\n",
    "        print (\">>> La imagen No. {} está etiquetado como Mujer\".format(index_img))\n",
    "\n",
    "def get_new_colmns(data_x_tmp):\n",
    "    new_colmns = 1\n",
    "    for i in range(3):\n",
    "        new_colmns *= data_x_tmp.shape[i+1]\n",
    "    return new_colmns\n",
    "\n",
    "def  x_reshape_and_normalize(data_x_tmp):\n",
    "    rows = data_x_tmp.shape[0]\n",
    "    new_colmns = get_new_colmns(data_x_tmp)\n",
    "    data_x = data_x_tmp.reshape((rows,new_colmns))\n",
    "    colmns = data_x.shape[1]\n",
    "    print(\"Nuevas dimensiónes de X {}\".format(data_x.shape))\n",
    "    print('\\n>>> Datos de X sin normalizar: \\r\\n {}\\n'.format(data_x))\n",
    "    # Normalizamos los datos.\n",
    "    data_x = data_x/255 \n",
    "    print('>>> Datos de X normalizados: \\r\\n {}\\n'.format(data_x))\n",
    "    return data_x, rows, colmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtencion y normalizacion de datos\n",
    "ruta = ('dataset/data.pckl')\n",
    "index_img = 14000  ### Se puede cambiar el indice (0-258)\n",
    "def dataset_init(ruta, index_img):\n",
    "    data_x_tmp, data_y = charge_dataset(ruta)\n",
    "    print(\"Dimensión de X {}\".format(data_x_tmp.shape))\n",
    "    print(\"Dimensión de Y {}\".format(data_y.shape))\n",
    "    show_img(data_x_tmp, data_y, index_img)\n",
    "    data_x, rows, colmns = x_reshape_and_normalize(data_x_tmp)\n",
    "    return data_x, data_y, rows, colmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de X (24032, 64, 64, 3)\n",
      "Dimensión de Y (24032, 1)\n",
      ">>> La imagen No. 14000 está etiquetado como Hombre.\n",
      "Nuevas dimensiónes de X (24032, 12288)\n",
      "\n",
      ">>> Datos de X sin normalizar: \n",
      " [[ 25  21  18 ...  61  65  45]\n",
      " [241 240 232 ... 222 228 233]\n",
      " [ 87  97  73 ...  65  65  40]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   2 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "\n",
      ">>> Datos de X normalizados: \n",
      " [[0.09803922 0.08235294 0.07058824 ... 0.23921569 0.25490196 0.17647059]\n",
      " [0.94509804 0.94117647 0.90980392 ... 0.87058824 0.89411765 0.91372549]\n",
      " [0.34117647 0.38039216 0.28627451 ... 0.25490196 0.25490196 0.15686275]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00784314 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtengo mis datos\n",
    "data_x, data_y_tmp, rows, colmns = dataset_init(ruta, index_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joseo\\Anaconda3\\envs\\automatas\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "oneHot = OneHotEncoder()\n",
    "oneHot.fit(data_y_tmp)\n",
    "data_y = oneHot.transform(data_y_tmp).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(data_y[index_img,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(19225, 12288), Validation:(2404, 12288), Test (2403, 12288)\n",
      "<class 'numpy.ndarray'>\n",
      "(19225, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_tmp, Y_train, Y_tmp = tts(data_x, data_y, test_size=0.2, random_state=None) \n",
    "X_test, X_validation, Y_test, Y_validation = tts(X_tmp, Y_tmp, test_size=0.5, random_state=None) \n",
    "X_train = np.array(X_train)\n",
    "X_validation = np.array(X_validation)\n",
    "X_test = np.array(X_test)\n",
    "print('Train:{}, Validation:{}, Test {}'.format(X_train.shape,X_validation.shape,X_test.shape))\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'dataset/test_data.pckl'\n",
    "File = open(ruta, 'wb')\n",
    "pickle.dump(X_test,File) \n",
    "pickle.dump(Y_test,File)\n",
    "File.close()\n",
    "del(File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2404"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.shape(X_train)[0]\n",
    "learning_rate = 0.0009\n",
    "num_epochs = 50\n",
    "display_step = 1\n",
    "hidden_layer_size = 300          # Número de neuronas en capa oculta\n",
    "n = np.shape(X_train)[1]         # Número de cararcteristicas\n",
    "n_class = np.shape(Y_train)[1]   # Número de clases\n",
    "#batch_sz = int(samples*0.1)\n",
    "batch_sz = 2404\n",
    "n_batches = int(samples/batch_sz)\n",
    "batch_sz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [batch_sz, 64, 64, 3])\n",
    "Y = tf.placeholder(tf.float32, [batch_sz, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1116 17:38:01.120532  9996 deprecation.py:506] From C:\\Users\\joseo\\Anaconda3\\envs\\automatas\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.get_variable(\"W1\", [8, 8, 3, 32])\n",
    "b1 = tf.get_variable(\"b1\", 32)\n",
    "W2 = tf.get_variable(\"W2\",[8, 8, 32, 64])\n",
    "b2 = tf.get_variable(\"b2\", 64)\n",
    "W3 = tf.get_variable(\"W3\",[16*16*64, hidden_layer_size])\n",
    "b3 = tf.get_variable(\"b3\",[hidden_layer_size])\n",
    "W4 = tf.get_variable(\"W4\",[hidden_layer_size, n_class])\n",
    "b4 = tf.get_variable(\"b4\",n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = convpool(X, W1, b1)\n",
    "Z2 = convpool(Z1, W2, b2)\n",
    "Z2_shape = Z2.get_shape().as_list()\n",
    "Z2r = tf.reshape(Z2, [Z2_shape[0], np.prod(Z2_shape[1:])])\n",
    "Z3 = tf.nn.relu( tf.matmul(Z2r, W3) + b3 )\n",
    "Z = tf.matmul(Z3, W4) + b4\n",
    "y_ = tf.nn.tanh(Z)\n",
    "prediccion = tf.equal(tf.argmax(y_, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=Z)\n",
    "mean_J = tf.reduce_mean(J)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mean_J)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(mean_J)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(prediccion, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2404), Dimension(64), Dimension(64), Dimension(3)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train_cost=0.8386 validation_cost=0.8149 validation_accuracy=50.37\n",
      "Epoch: 2 train_cost=0.7052 validation_cost=0.6528 validation_accuracy=67.01\n",
      "Epoch: 3 train_cost=0.5384 validation_cost=0.5441 validation_accuracy=74.46\n",
      "Epoch: 4 train_cost=0.4893 validation_cost=0.4970 validation_accuracy=77.16\n",
      "Epoch: 5 train_cost=0.4587 validation_cost=0.4619 validation_accuracy=77.87\n",
      "Epoch: 6 train_cost=0.4458 validation_cost=0.4440 validation_accuracy=78.54\n",
      "Epoch: 7 train_cost=0.4362 validation_cost=0.4336 validation_accuracy=78.91\n",
      "Epoch: 8 train_cost=0.4272 validation_cost=0.4286 validation_accuracy=79.24\n",
      "Epoch: 9 train_cost=0.4186 validation_cost=0.4205 validation_accuracy=79.74\n",
      "Epoch: 10 train_cost=0.4114 validation_cost=0.4112 validation_accuracy=80.45\n",
      "Epoch: 11 train_cost=0.4002 validation_cost=0.4027 validation_accuracy=80.57\n",
      "Epoch: 12 train_cost=0.3905 validation_cost=0.3894 validation_accuracy=81.49\n",
      "Epoch: 13 train_cost=0.3728 validation_cost=0.3773 validation_accuracy=81.82\n",
      "Epoch: 14 train_cost=0.3776 validation_cost=0.3735 validation_accuracy=81.95\n",
      "Epoch: 15 train_cost=0.3710 validation_cost=0.3788 validation_accuracy=82.24\n",
      "Epoch: 16 train_cost=0.3511 validation_cost=0.3711 validation_accuracy=82.24\n",
      "Epoch: 17 train_cost=0.3537 validation_cost=0.3493 validation_accuracy=83.49\n",
      "Epoch: 18 train_cost=0.3349 validation_cost=0.3433 validation_accuracy=83.69\n",
      "Epoch: 19 train_cost=0.3294 validation_cost=0.3357 validation_accuracy=84.28\n",
      "Epoch: 20 train_cost=0.3215 validation_cost=0.3357 validation_accuracy=84.82\n",
      "Epoch: 21 train_cost=0.3109 validation_cost=0.3367 validation_accuracy=84.36\n",
      "Epoch: 22 train_cost=0.3132 validation_cost=0.3194 validation_accuracy=85.48\n",
      "Epoch: 23 train_cost=0.2892 validation_cost=0.3125 validation_accuracy=85.94\n",
      "Epoch: 24 train_cost=0.2832 validation_cost=0.3064 validation_accuracy=86.06\n",
      "Epoch: 25 train_cost=0.2747 validation_cost=0.2989 validation_accuracy=86.73\n",
      "Epoch: 26 train_cost=0.2666 validation_cost=0.3039 validation_accuracy=86.19\n",
      "Epoch: 27 train_cost=0.2527 validation_cost=0.2859 validation_accuracy=87.52\n",
      "Epoch: 28 train_cost=0.2464 validation_cost=0.2798 validation_accuracy=87.98\n",
      "Epoch: 29 train_cost=0.2365 validation_cost=0.2771 validation_accuracy=87.44\n",
      "Epoch: 30 train_cost=0.2261 validation_cost=0.2938 validation_accuracy=86.94\n",
      "Epoch: 31 train_cost=0.2135 validation_cost=0.2758 validation_accuracy=88.23\n",
      "Epoch: 32 train_cost=0.2039 validation_cost=0.2767 validation_accuracy=87.98\n",
      "Epoch: 33 train_cost=0.1952 validation_cost=0.2773 validation_accuracy=87.98\n",
      "Epoch: 34 train_cost=0.1840 validation_cost=0.2704 validation_accuracy=88.39\n",
      "Epoch: 35 train_cost=0.1706 validation_cost=0.2577 validation_accuracy=89.06\n",
      "Epoch: 36 train_cost=0.1772 validation_cost=0.2943 validation_accuracy=87.40\n",
      "Epoch: 37 train_cost=0.1702 validation_cost=0.2881 validation_accuracy=87.98\n",
      "Epoch: 38 train_cost=0.1570 validation_cost=0.2753 validation_accuracy=88.39\n",
      "Epoch: 39 train_cost=0.1505 validation_cost=0.2763 validation_accuracy=88.52\n",
      "Epoch: 40 train_cost=0.1408 validation_cost=0.2821 validation_accuracy=88.73\n",
      "Epoch: 41 train_cost=0.1376 validation_cost=0.2794 validation_accuracy=88.56\n",
      "Epoch: 42 train_cost=0.1527 validation_cost=0.2536 validation_accuracy=89.77\n",
      "Epoch: 43 train_cost=0.1456 validation_cost=0.2669 validation_accuracy=89.43\n",
      "Epoch: 44 train_cost=0.1258 validation_cost=0.2470 validation_accuracy=90.14\n",
      "Epoch: 45 train_cost=0.1116 validation_cost=0.2575 validation_accuracy=90.31\n",
      "Epoch: 46 train_cost=0.1028 validation_cost=0.2527 validation_accuracy=90.56\n",
      "Epoch: 47 train_cost=0.0980 validation_cost=0.2547 validation_accuracy=90.77\n",
      "Epoch: 48 train_cost=0.0922 validation_cost=0.2547 validation_accuracy=90.89\n",
      "Epoch: 49 train_cost=0.0857 validation_cost=0.2618 validation_accuracy=90.43\n",
      "Epoch: 50 train_cost=0.0790 validation_cost=0.2620 validation_accuracy=90.68\n",
      "Entrenamiento Finalizado\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2403, 12288) for Tensor 'Placeholder:0', which has shape '(2404, 64, 64, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e5efe69ca271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Entrenamiento Finalizado'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         v_cost, v_accuracy = sess.run([mean_J, accuracy], \n\u001b[1;32m---> 34\u001b[1;33m                                         feed_dict={X: X_test, Y: Y_test})\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluación del modelo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_cost={:0.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test_accuracy={:0.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_accuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\automatas\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\automatas\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1149\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1150\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (2403, 12288) for Tensor 'Placeholder:0', which has shape '(2404, 64, 64, 3)'"
     ]
    }
   ],
   "source": [
    "train_cost = []\n",
    "validation_cost = []\n",
    "prev_validation_accuracy = 0\n",
    "with tf.name_scope(\"starting_tensorflow_session\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        cont = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in range(n_batches):\n",
    "                X_batch = X_train[batch*batch_sz:(batch*batch_sz + batch_sz),:]\n",
    "                Y_batch = Y_train[batch*batch_sz:(batch*batch_sz + batch_sz),:]\n",
    "                X_batch = X_batch.reshape(X_batch.shape[0], 64, 64, 3)\n",
    "                #print(X_batch.shape)\n",
    "                _, t_cost = sess.run([optimizer, mean_J], feed_dict={X: X_batch, Y: Y_batch})\n",
    "                train_cost.append(t_cost)\n",
    "  \n",
    "            X_validation = X_validation.reshape(X_validation.shape[0], 64, 64, 3)   \n",
    "            v_cost, v_accuracy = sess.run([mean_J, accuracy], \n",
    "                                        feed_dict={X: X_validation, Y: Y_validation})\n",
    "            validation_cost.append(v_cost)\n",
    "            if (epoch+1) % display_step == 0:\n",
    "                print(\"Epoch: {}\".format(epoch + 1), \"train_cost={:0.4f}\".format(t_cost), \n",
    "                      \"validation_cost={:0.4f}\".format(v_cost), \"validation_accuracy={:0.2f}\".format(v_accuracy*100))\n",
    "            if v_accuracy <= prev_validation_accuracy:\n",
    "                cont = cont+1;\n",
    "            else:\n",
    "                cont = 0\n",
    "            if cont > 2:\n",
    "                break\n",
    "            prev_validation_accuracy = v_accuracy\n",
    "            saver.save(sess, os.getcwd()+\"/modeloCNN.ckpt\")\n",
    "        print('Entrenamiento Finalizado')\n",
    "        X_test = X_test.reshape(X_test.shape[0], 64, 64, 3)\n",
    "        v_cost, v_accuracy = sess.run([mean_J, accuracy], \n",
    "                                        feed_dict={X: X_test, Y: Y_test})\n",
    "        print(\"Evaluación del modelo\")\n",
    "        print(\"test_cost={:0.4f}\".format(v_cost), \"test_accuracy={:0.2f}\".format(v_accuracy*100))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                \n",
    "               \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          if (epoch+1) % display_step == 0:\n",
    "                print(\"Epoch: {}\".format(epoch + 1), \"train_cost={:0.4f}\".format(t_cost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
